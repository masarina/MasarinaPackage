


class PytorchDebuger:
    def __init__(self):
        pass
        
    def compare_model_optimizer_shapes(model, optimizer):
        """
        ãƒ¢ãƒ‡ãƒ«ã®å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é‡ã¿ã€ãƒã‚¤ã‚¢ã‚¹ã€ãƒ™ãƒ¼ã‚¿å€¤ã®shapeã‚’Optimizerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã€
        ä¸ä¸€è‡´ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åå‰ã¨shapeã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã€‚
    
        Args:
            model (torch.nn.Module): PyTorchãƒ¢ãƒ‡ãƒ«
            optimizer (torch.optim.Optimizer): Optimizer
        """
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        model_params = {name: param.shape for name, param in model.named_parameters()}
    
        # Optimizerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        optimizer_params = {f"optimizer_{i}": p.shape for i, p in enumerate(optimizer.param_groups[0]['params'])}
    
        # æ¯”è¼ƒçµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
        mismatched_layers = []
    
        print("ã€Shapeæ¯”è¼ƒçµæœã€‘")
        print("-" * 50)
    
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨Optimizerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒ
        for name, model_shape in model_params.items():
            # Optimizerãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨Shapeã‚’æ¯”è¼ƒ
            match_found = any(model_shape == opt_shape for opt_shape in optimizer_params.values())
    
            if not match_found:
                mismatched_layers.append((name, model_shape))
                print(f"ä¸ä¸€è‡´ãƒ¬ã‚¤ãƒ¤ãƒ¼: {name}, Shape: {model_shape}")
    
        if not mismatched_layers:
            print("å…¨ã¦ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ShapeãŒOptimizerã«ä¸€è‡´ã—ã¦ã„ã¾ã™ï¼ğŸ‰")
        else:
            print("\nã€ä¸ä¸€è‡´ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ä¸€è¦§ã€‘")
            for layer_name, shape in mismatched_layers:
                print(f"ãƒ¬ã‚¤ãƒ¤ãƒ¼å: {layer_name}, Shape: {shape}")
    